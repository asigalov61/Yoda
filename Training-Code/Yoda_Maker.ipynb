{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "ac5a4cf0-d9d2-47b5-9633-b53f8d99a4d2",
          "kernelId": ""
        },
        "id": "SiTIpPjArIyr"
      },
      "source": [
        "# Yoda Maker (ver. 2.0)\n",
        "\n",
        "***\n",
        "\n",
        "Powered by tegridy-tools TMIDIX Optimus Processors: https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "***\n",
        "\n",
        "Credit for GPT2-RGA code used in this colab goes out @ Sashmark97 https://github.com/Sashmark97/midigen and @ Damon Gwinn https://github.com/gwinndr/MusicTransformer-Pytorch\n",
        "\n",
        "***\n",
        "\n",
        "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2022\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "fa0a611c-1803-42ae-bdf6-a49b5a4e781b",
          "kernelId": ""
        },
        "id": "gOd93yV0sGd2"
      },
      "source": [
        "# (Setup Environment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "39411b40-9e39-416e-8fe4-d40f733e7956",
          "kernelId": ""
        },
        "id": "lw-4aqV3sKQG"
      },
      "outputs": [],
      "source": [
        "#@title nvidia-smi gpu check\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "a1a45a91-d909-4fd4-b67a-5e16b971d179",
          "kernelId": ""
        },
        "id": "fX12Yquyuihc"
      },
      "outputs": [],
      "source": [
        "#@title Install all dependencies (run only once per session)\n",
        "\n",
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "b8207b76-9514-4c07-95db-95a4742e52c5",
          "kernelId": ""
        },
        "id": "z7n9vnKmug1J"
      },
      "outputs": [],
      "source": [
        "#@title Import all needed modules\n",
        "\n",
        "print('Loading needed modules. Please wait...')\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "print('Loading TMIDIX module...')\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\n",
        "import TMIDIX\n",
        "\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\n",
        "from GPT2RGAX import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.chdir('/content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "20b8698a-0b4e-4fdb-ae49-24d063782e77",
          "kernelId": ""
        },
        "id": "ObPxlEutsQBj"
      },
      "source": [
        "# (FROM SCRATCH) Download and process MIDI dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "ffbb7a2a-d91a-477f-ac89-56d77d6cdf42",
          "kernelId": ""
        },
        "id": "snIZ3xKPsPgB"
      },
      "outputs": [],
      "source": [
        "#@title Download original LAKH/clean_midi MIDI subset (Recommended)\n",
        "\n",
        "#@markdown Works best stand-alone/as-is for the optimal results\n",
        "%cd /content/\n",
        "\n",
        "!wget 'http://hog.ee.columbia.edu/craffel/lmd/clean_midi.tar.gz'\n",
        "!tar -xvf 'clean_midi.tar.gz'\n",
        "!rm 'clean_midi.tar.gz'\n",
        "\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "id": "ed07b44f-07fe-45fb-a64f-adba8df1bdcb",
          "kernelId": ""
        },
        "id": "on7sgKEP3Yc8"
      },
      "outputs": [],
      "source": [
        "#@title Process MIDIs to special MIDI dataset with TMIDIX MIDI Processor\n",
        "\n",
        "#@title Process MIDIs\n",
        "\n",
        "sorted_or_random_file_loading_order = False # Sorted order is NOT usually recommended\n",
        "dataset_ratio = 1 # Change this if you need more data\n",
        "\n",
        "\n",
        "print('TMIDIX MIDI Processor')\n",
        "print('Starting up...')\n",
        "###########\n",
        "\n",
        "files_count = 0\n",
        "\n",
        "gfiles = []\n",
        "\n",
        "melody_chords_f = []\n",
        "\n",
        "###########\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"./clean_midi/\"\n",
        "# os.chdir(dataset_addr)\n",
        "filez = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
        "    filez += [os.path.join(dirpath, file) for file in filenames]\n",
        "print('=' * 70)\n",
        "\n",
        "if filez == []:\n",
        "    print('Could not find any MIDI files. Please check Dataset dir...')\n",
        "    print('=' * 70)\n",
        "\n",
        "if sorted_or_random_file_loading_order:\n",
        "    print('Sorting files...')\n",
        "    filez.sort()\n",
        "    print('Done!')\n",
        "    print('=' * 70)\n",
        "else:\n",
        "    print('Randomizing file list...')\n",
        "    random.shuffle(filez)\n",
        "\n",
        "    \n",
        "stats = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "for f in tqdm(filez[:int(len(filez) * dataset_ratio)]):\n",
        "    try:\n",
        "        fn = os.path.basename(f)\n",
        "        fn1 = fn.split('.')[0]\n",
        "\n",
        "        files_count += 1\n",
        "\n",
        "        #print('Loading MIDI file...')\n",
        "        score = TMIDIX.midi2ms_score(open(f, 'rb').read())\n",
        "\n",
        "        events_matrix = []\n",
        "\n",
        "        itrack = 1\n",
        "\n",
        "        patches = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "        patch_map = [[0, 1, 2, 3, 4, 5, 6, 7], # Piano \n",
        "                     [24, 25, 26, 27, 28, 29, 30], # Guitar\n",
        "                     [32, 33, 34, 35, 36, 37, 38, 39], # Bass\n",
        "                     [40, 41], # Violin\n",
        "                     [42, 43], # Cello\n",
        "                     [46], # Harp\n",
        "                     [56, 57, 58, 59, 60], # Trumpet\n",
        "                     [71, 72], # Clarinet\n",
        "                     [73, 74, 75], # Flute\n",
        "                     [-1], # Fake Drums\n",
        "                     [52, 53] # Choir\n",
        "                    ]\n",
        "\n",
        "        while itrack < len(score):\n",
        "            for event in score[itrack]:         \n",
        "                if event[0] == 'note' or event[0] == 'patch_change':\n",
        "                    events_matrix.append(event)\n",
        "            itrack += 1\n",
        "\n",
        "        events_matrix1 = []\n",
        "        for event in events_matrix:\n",
        "                if event[0] == 'patch_change':\n",
        "                    patches[event[2]] = event[3]\n",
        "\n",
        "                if event[0] == 'note':\n",
        "                    event.extend([patches[event[3]]])\n",
        "                    once = False\n",
        "                    \n",
        "                    for p in patch_map:\n",
        "                        if event[6] in p and event[3] != 9: # Except the drums\n",
        "                            event[3] = patch_map.index(p)\n",
        "                            once = True\n",
        "                            \n",
        "                    if not once and event[3] != 9: # Except the drums\n",
        "                        event[3] = 0 # All other instruments/patches channel\n",
        "                        event[5] = max(80, event[5])\n",
        "                        \n",
        "                    if event[3] < 11: # We won't write chans 11-16 for now...\n",
        "                        events_matrix1.append(event)\n",
        "                        stats[event[3]] += 1\n",
        "\n",
        "        # recalculating timings\n",
        "        \n",
        "        for e in events_matrix1:\n",
        "            e[1] = int(e[1] / 16)\n",
        "            e[2] = int(e[2] / 128)\n",
        "        \n",
        "        # final processing...\n",
        "\n",
        "        if len(events_matrix1) > 0:\n",
        "            \n",
        "            events_matrix1.sort(key=lambda x: (x[1], x[4]))\n",
        "\n",
        "            cho = []\n",
        "            pe = events_matrix1[0]\n",
        "            melody_chords = []\n",
        "            for e in events_matrix1:\n",
        "\n",
        "                time = max(0, min(255, e[1]-pe[1]))\n",
        "                dur = max(0, min(15, e[2]))\n",
        "                cha = max(0, min(15, e[3]))\n",
        "                ptc = max(0, min(127, e[4]))\n",
        "                vel = max(0, min(127, e[5]))\n",
        "\n",
        "                melody_chords.append([time, dur, ptc, cha, vel])\n",
        "\n",
        "                pe = e\n",
        "            melody_chords_f.append(melody_chords)\n",
        "\n",
        "        gfiles.append(f)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('Saving current progress and quitting...')\n",
        "        break  \n",
        "\n",
        "    except:\n",
        "        print('Bad MIDI:', f)\n",
        "        continue\n",
        "print('=' * 70)\n",
        "        \n",
        "print('Done!')   \n",
        "print('=' * 70)\n",
        "\n",
        "print('Resulting Stats:')\n",
        "print('=' * 70)\n",
        "\n",
        "print('Piano:', stats[0])\n",
        "print('Guitar:', stats[1])\n",
        "print('Bass:', stats[2])\n",
        "print('Violin:', stats[3])\n",
        "print('Cello:', stats[4])\n",
        "print('Harp:', stats[5])\n",
        "print('Trumpet:', stats[6])\n",
        "print('Clarinet:', stats[7])\n",
        "print('Flute:', stats[8])\n",
        "print('Drums:', stats[9])\n",
        "print('Choir:', stats[10])\n",
        "\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "3ee97039-6ebe-4896-846c-4564d7ee16cf",
          "kernelId": ""
        },
        "id": "Bsf5FZBAHX9y"
      },
      "outputs": [],
      "source": [
        "TMIDIX.Tegridy_Any_Pickle_File_Writer(melody_chords_f, '/content/Yoda_Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "0553db32-585b-48bc-abd2-8b9aebde5c8f",
          "kernelId": ""
        },
        "id": "jYW3B-kWHX9y"
      },
      "outputs": [],
      "source": [
        "melody_chords_f = TMIDIX.Tegridy_Any_Pickle_File_Reader('/content/Yoda_Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "0826f622-2edc-4f09-9a01-58df049738d4",
          "kernelId": ""
        },
        "id": "t-jV34sBHX9z"
      },
      "outputs": [],
      "source": [
        "# Process and prep INTs...\n",
        "\n",
        "randomize_dataset = True\n",
        "\n",
        "print('=' * 70)\n",
        "print('Prepping INTs dataset...')\n",
        "\n",
        "if randomize_dataset:\n",
        "    print('=' * 70)\n",
        "    print('Randomizing the dataset...')\n",
        "    random.shuffle(melody_chords_f)\n",
        "    print('Done!')\n",
        "    \n",
        "print('=' * 70)\n",
        "print('Processing the dataset...')\n",
        "\n",
        "train_data1 = []\n",
        "\n",
        "for chords_list in tqdm(melody_chords_f):\n",
        "    \n",
        "    train_data1.extend([0]) # Intro/Zero Token\n",
        "    \n",
        "    for i in chords_list:\n",
        "\n",
        "        if i[0] != 0: # This is the chordification line\n",
        "            train_data1.extend([i[0]]) # start-times\n",
        "            \n",
        "        # And this is the main MIDI note line (triple stack)\n",
        "        main_note = [i[1] + (i[2] * 16) + (i[3] * 16 * 128)] # Main note == [duration / pitch / channel]\n",
        "        \n",
        "        if main_note != [0]: # Main note error control...\n",
        "            train_data1.extend(main_note) # Main note == [duration / pitch / channel]\n",
        "\n",
        "print('Done!')        \n",
        "print('=' * 70)\n",
        "        \n",
        "print('Total INTs:', len(train_data1))\n",
        "print('Minimum INT:', min(train_data1))\n",
        "print('Maximum INT:', max(train_data1))\n",
        "print('Unique INTs:', len(set(train_data1)))\n",
        "print('Intro/Zero INTs:', train_data1.count(0))\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "id": "53252e52-5e68-4e60-8e4d-a584667749a4",
          "kernelId": ""
        },
        "id": "lT0TyqUnpxu_"
      },
      "outputs": [],
      "source": [
        "#@title Load processed INTs datasets\n",
        "\n",
        "SEQ_LEN = max_seq # Change this to your specs\n",
        "BATCH_SIZE = 1 # Change this to your specs\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "print('=' * 50)\n",
        "print('Loading training data...')\n",
        "\n",
        "data_train, data_val = torch.Tensor(train_data1), torch.Tensor(train_data1[:SEQ_LEN * 4])\n",
        "\n",
        "class MusicSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len - 1, (1,))\n",
        "        max_seq = self.data[rand_start: rand_start + self.seq_len].long()\n",
        "        full_seq = self.data[rand_start+1: rand_start + self.seq_len + 1].long()\n",
        "        return max_seq, full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "train_dataset = MusicSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = MusicSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
        "val_loader    = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
        "\n",
        "print('Total INTs in the dataset', len(train_data1))\n",
        "print('Total unique INTs in the dataset', len(set(train_data1)))\n",
        "print('Max INT in the dataset', max(train_data1))\n",
        "print('Min INT in the dataset', min(train_data1))\n",
        "print('=' * 50)\n",
        "\n",
        "print('Length of the dataset:',len(train_dataset))\n",
        "print('Length of data loader',len(train_loader))\n",
        "print('=' * 50)\n",
        "print('Done! Enjoy! :)')\n",
        "print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ye9rNzOHX90"
      },
      "source": [
        "# Test the resulting INTs dataset..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "708f16d3-1747-4e72-bcc9-7504cdd963d4",
          "kernelId": ""
        },
        "id": "IvL-AX6fHX90"
      },
      "outputs": [],
      "source": [
        "train_data1[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "execution_count": 6,
          "id": "dd411e56-532f-47dd-8283-ecb57126a3ae",
          "kernelId": ""
        },
        "id": "p14gn48SHX90"
      },
      "outputs": [],
      "source": [
        "out = train_data1[:16000]\n",
        "\n",
        "if len(out) != 0:\n",
        "    \n",
        "    song = out\n",
        "    song_f = []\n",
        "    time = 0\n",
        "    dur = 0\n",
        "    vel = 0\n",
        "    pitch = 0\n",
        "    channel = 0\n",
        "    \n",
        "    for s in song:\n",
        "        if s < 256:\n",
        "            time += s * 16\n",
        "            \n",
        "        else:\n",
        "            channel = s // 16 // 128\n",
        "\n",
        "            pitch = (s // 16) % 128\n",
        "            \n",
        "            dur = ((s % 16) * 128) + 128\n",
        "            \n",
        "            # Velocities for each channel:\n",
        "            if channel == 0:  # Piano     \n",
        "                vel = 60\n",
        "            if channel == 1:  # Guitar     \n",
        "                vel = 70            \n",
        "            if channel == 2:  # Bass     \n",
        "                vel = 60            \n",
        "            if channel == 3:  # Violin\n",
        "                vel = 90            \n",
        "            if channel == 4:  # Cello     \n",
        "                vel = 100\n",
        "            if channel == 5:  # Harp     \n",
        "                vel = 80\n",
        "            if channel == 6:  # Trumpet     \n",
        "                vel = 100            \n",
        "            if channel == 7:  # Clarinet     \n",
        "                vel = 100           \n",
        "            if channel == 8:  # Flute\n",
        "                vel = 100                          \n",
        "            if channel == 9:  # Drums\n",
        "                vel = 80            \n",
        "            if channel == 10:  # Choir     \n",
        "                vel = 110                  \n",
        "                               \n",
        "            song_f.append(['note', time, dur, channel, pitch, vel ])\n",
        "\n",
        "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
        "                                                        output_signature = 'Yoda',  \n",
        "                                                        output_file_name = '/content/Yoda-Music-Composition', \n",
        "                                                        track_name='Project Los Angeles',\n",
        "                                                        list_of_MIDI_patches=[0, 24, 32, 40, 42, 46, 56, 71, 73, 0, 53, 0, 0, 0, 0, 0],\n",
        "                                                        number_of_ticks_per_quarter=500)\n",
        "\n",
        "    print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkVqviDzJOrv"
      },
      "source": [
        "# (TRAIN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9CBW8xYupH8"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "4aa21407-a3e9-4ed2-9bf1-83c295482b8a",
          "kernelId": ""
        },
        "id": "2moo7uUmpxvC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Train\n",
        "\n",
        "DIC_SIZE = max(train_data1)+1\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "config = GPTConfig(DIC_SIZE, \n",
        "                   max_seq,\n",
        "                   dim_feedforward=512,\n",
        "                   n_layer=6, \n",
        "                   n_head=8, \n",
        "                   n_embd=512,\n",
        "                   enable_rpr=True,\n",
        "                   er_len=max_seq)\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = GPT(config)\n",
        "\n",
        "model = nn.DataParallel(model)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "#=====\n",
        "\n",
        "init_step = 0\n",
        "lr = LR_DEFAULT_START\n",
        "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
        "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
        "train_loss_func = eval_loss_func\n",
        "\n",
        "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
        "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
        "\n",
        "\n",
        "#===\n",
        "\n",
        "best_eval_acc        = 0.0\n",
        "best_eval_acc_epoch  = -1\n",
        "best_eval_loss       = float(\"inf\")\n",
        "best_eval_loss_epoch = -1\n",
        "best_acc_file = '/content/gpt2_rpr_acc.pth'\n",
        "best_loss_file = '/content/gpt2_rpr_loss.pth'\n",
        "loss_train, loss_val, acc_val = [], [], []\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    new_best = False\n",
        "    \n",
        "    loss = train(epoch+1, \n",
        "                 model, train_loader, \n",
        "                 train_loss_func, \n",
        "                 opt, \n",
        "                 lr_scheduler, \n",
        "                 num_iters=-1, \n",
        "                 save_checkpoint_steps=4000)\n",
        "    \n",
        "    loss_train.append(loss)\n",
        "    \n",
        "    eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)\n",
        "    loss_val.append(eval_loss)\n",
        "    acc_val.append(eval_acc)\n",
        "    \n",
        "    if(eval_acc > best_eval_acc):\n",
        "        best_eval_acc = eval_acc\n",
        "        best_eval_acc_epoch  = epoch+1\n",
        "        torch.save(model.state_dict(), best_acc_file)\n",
        "        new_best = True\n",
        "\n",
        "    if(eval_loss < best_eval_loss):\n",
        "        best_eval_loss       = eval_loss\n",
        "        best_eval_loss_epoch = epoch+1\n",
        "        torch.save(model.state_dict(), best_loss_file)\n",
        "        new_best = True\n",
        "    \n",
        "    if(new_best):\n",
        "        print(\"Best eval acc epoch:\", best_eval_acc_epoch)\n",
        "        print(\"Best eval acc:\", best_eval_acc)\n",
        "        print(\"\")\n",
        "        print(\"Best eval loss epoch:\", best_eval_loss_epoch)\n",
        "        print(\"Best eval loss:\", best_eval_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "72338f3f-34c4-40e3-a48a-42ed9729466a",
          "kernelId": ""
        },
        "id": "R4LIXk1vHX92"
      },
      "outputs": [],
      "source": [
        "# Eval funct to eval separately if needed\n",
        "\n",
        "#=====\n",
        "\n",
        "init_step = 0\n",
        "lr = LR_DEFAULT_START\n",
        "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
        "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
        "train_loss_func = eval_loss_func\n",
        "\n",
        "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
        "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
        "\n",
        "\n",
        "eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "id": "0e338550-f170-44a6-9479-ba0ddbc64608",
          "kernelId": ""
        },
        "id": "NNqmcFdRyC2M"
      },
      "outputs": [],
      "source": [
        "#@title Plot resulting training loss graph\n",
        "\n",
        "tr_loss_list = [item for sublist in loss_train for item in sublist]\n",
        "plt.plot([i for i in range(len(tr_loss_list))] ,tr_loss_list, 'b')\n",
        "plt.savefig('/content/Yoda-Training-Loss-Graph.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdKFoeke9L7H"
      },
      "source": [
        "# (SAVE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "id": "73bea62d-084b-4f9a-9e55-2b34a932a7a4",
          "kernelId": ""
        },
        "id": "gqyDatHC9X1z"
      },
      "outputs": [],
      "source": [
        "#@title Save the model\n",
        "\n",
        "print('Saving the model...')\n",
        "full_path_to_model_checkpoint = \"/content/Yoda-Trained-Model.pth\" #@param {type:\"string\"}\n",
        "torch.save(model.state_dict(), full_path_to_model_checkpoint)\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzCMd94Tu_gz"
      },
      "source": [
        "# Congrats! You did it! :)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Yoda_Maker.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}