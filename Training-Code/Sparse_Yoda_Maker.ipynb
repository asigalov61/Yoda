{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "ac5a4cf0-d9d2-47b5-9633-b53f8d99a4d2",
          "kernelId": ""
        },
        "id": "SiTIpPjArIyr"
      },
      "source": [
        "# Sparse Yoda Maker (ver. 2.0)\n",
        "\n",
        "***\n",
        "\n",
        "Powered by tegridy-tools: https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "***\n",
        "\n",
        "Credit for the Sparse Trainsformer implementation used in this colab goes out @lucidrains https://github.com/lucidrains/sinkhorn-transformer\n",
        "\n",
        "***\n",
        "\n",
        "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2022\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "fa0a611c-1803-42ae-bdf6-a49b5a4e781b",
          "kernelId": ""
        },
        "id": "gOd93yV0sGd2"
      },
      "source": [
        "# (Setup Environment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "39411b40-9e39-416e-8fe4-d40f733e7956",
          "kernelId": ""
        },
        "id": "lw-4aqV3sKQG"
      },
      "outputs": [],
      "source": [
        "#@title nvidia-smi gpu check\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "a1a45a91-d909-4fd4-b67a-5e16b971d179",
          "kernelId": ""
        },
        "id": "fX12Yquyuihc"
      },
      "outputs": [],
      "source": [
        "#@title Install all dependencies (run only once per session)\n",
        "\n",
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "!pip install sinkhorn_transformer\n",
        "\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "b8207b76-9514-4c07-95db-95a4742e52c5",
          "kernelId": ""
        },
        "id": "z7n9vnKmug1J"
      },
      "outputs": [],
      "source": [
        "#@title Import all needed modules\n",
        "\n",
        "print('Loading needed modules. Please wait...')\n",
        "import os\n",
        "import random\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from sinkhorn_transformer import SinkhornTransformerLM\n",
        "from sinkhorn_transformer.autoregressive_wrapper import AutoregressiveWrapper\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "print('Loading TMIDIX module...')\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\n",
        "import TMIDIX\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.chdir('/content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "20b8698a-0b4e-4fdb-ae49-24d063782e77",
          "kernelId": ""
        },
        "id": "ObPxlEutsQBj"
      },
      "source": [
        "# (FROM SCRATCH) Download and process MIDI dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "ffbb7a2a-d91a-477f-ac89-56d77d6cdf42",
          "kernelId": ""
        },
        "id": "snIZ3xKPsPgB"
      },
      "outputs": [],
      "source": [
        "#@title Download original LAKH/clean_midi MIDI subset (Recommended)\n",
        "\n",
        "#@markdown Works best stand-alone/as-is for the optimal results\n",
        "%cd /content/\n",
        "\n",
        "!wget 'http://hog.ee.columbia.edu/craffel/lmd/clean_midi.tar.gz'\n",
        "!tar -xvf 'clean_midi.tar.gz'\n",
        "!rm 'clean_midi.tar.gz'\n",
        "\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "ed07b44f-07fe-45fb-a64f-adba8df1bdcb",
          "kernelId": ""
        },
        "id": "on7sgKEP3Yc8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Process MIDIs to special MIDI dataset with TMIDIX MIDI Processor\n",
        "\n",
        "#@title Process MIDIs\n",
        "\n",
        "sorted_or_random_file_loading_order = False # Sorted order is NOT usually recommended\n",
        "dataset_ratio = 1 # Change this if you need more data\n",
        "\n",
        "\n",
        "print('TMIDIX MIDI Processor')\n",
        "print('Starting up...')\n",
        "###########\n",
        "\n",
        "files_count = 0\n",
        "\n",
        "gfiles = []\n",
        "\n",
        "melody_chords_f = []\n",
        "\n",
        "###########\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"./clean_midi/\"\n",
        "# os.chdir(dataset_addr)\n",
        "filez = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
        "    filez += [os.path.join(dirpath, file) for file in filenames]\n",
        "print('=' * 70)\n",
        "\n",
        "if filez == []:\n",
        "    print('Could not find any MIDI files. Please check Dataset dir...')\n",
        "    print('=' * 70)\n",
        "\n",
        "if sorted_or_random_file_loading_order:\n",
        "    print('Sorting files...')\n",
        "    filez.sort()\n",
        "    print('Done!')\n",
        "    print('=' * 70)\n",
        "else:\n",
        "    print('Randomizing file list...')\n",
        "    random.shuffle(filez)\n",
        "\n",
        "    \n",
        "stats = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "for f in tqdm.tqdm(filez[:int(len(filez) * dataset_ratio)]):\n",
        "    try:\n",
        "        fn = os.path.basename(f)\n",
        "        fn1 = fn.split('.')[0]\n",
        "\n",
        "        files_count += 1\n",
        "\n",
        "        #print('Loading MIDI file...')\n",
        "        score = TMIDIX.midi2ms_score(open(f, 'rb').read())\n",
        "\n",
        "        events_matrix = []\n",
        "\n",
        "        itrack = 1\n",
        "\n",
        "        patches = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "        patch_map = [[0, 1, 2, 3, 4, 5, 6, 7], # Piano \n",
        "                     [24, 25, 26, 27, 28, 29, 30], # Guitar\n",
        "                     [32, 33, 34, 35, 36, 37, 38, 39], # Bass\n",
        "                     [40, 41], # Violin\n",
        "                     [42, 43], # Cello\n",
        "                     [46], # Harp\n",
        "                     [56, 57, 58, 59, 60], # Trumpet\n",
        "                     [71, 72], # Clarinet\n",
        "                     [73, 74, 75], # Flute\n",
        "                     [-1], # Fake Drums\n",
        "                     [52, 53] # Choir\n",
        "                    ]\n",
        "\n",
        "        while itrack < len(score):\n",
        "            for event in score[itrack]:         \n",
        "                if event[0] == 'note' or event[0] == 'patch_change':\n",
        "                    events_matrix.append(event)\n",
        "            itrack += 1\n",
        "\n",
        "        events_matrix1 = []\n",
        "        for event in events_matrix:\n",
        "                if event[0] == 'patch_change':\n",
        "                    patches[event[2]] = event[3]\n",
        "\n",
        "                if event[0] == 'note':\n",
        "                    event.extend([patches[event[3]]])\n",
        "                    once = False\n",
        "                    \n",
        "                    for p in patch_map:\n",
        "                        if event[6] in p and event[3] != 9: # Except the drums\n",
        "                            event[3] = patch_map.index(p)\n",
        "                            once = True\n",
        "                            \n",
        "                    if not once and event[3] != 9: # Except the drums\n",
        "                        event[3] = 0 # All other instruments/patches channel\n",
        "                        event[5] = max(80, event[5])\n",
        "                        \n",
        "                    if event[3] < 11: # We won't write chans 11-16 for now...\n",
        "                        events_matrix1.append(event)\n",
        "                        stats[event[3]] += 1\n",
        "\n",
        "        # recalculating timings\n",
        "        \n",
        "        for e in events_matrix1:\n",
        "            e[1] = int(e[1] / 10)\n",
        "            e[2] = int(e[2] / 20)\n",
        "        \n",
        "        # final processing...\n",
        "\n",
        "        if len(events_matrix1) > 0:\n",
        "            \n",
        "            events_matrix1.sort(key=lambda x: (x[1], x[4]))\n",
        "\n",
        "            cho = []\n",
        "            pe = events_matrix1[0]\n",
        "            melody_chords = []\n",
        "            for e in events_matrix1:\n",
        "\n",
        "                time = max(0, min(126, e[1]-pe[1]))\n",
        "                dur = max(0, min(126, e[2]))\n",
        "                cha = max(0, min(15, e[3]))\n",
        "                ptc = max(0, min(126, e[4]))\n",
        "                vel = max(0, min(126, e[5]))\n",
        "\n",
        "                melody_chords.append([time, dur, cha, ptc, vel])\n",
        "\n",
        "                pe = e\n",
        "            melody_chords_f.append(melody_chords)\n",
        "\n",
        "        gfiles.append(f)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('Saving current progress and quitting...')\n",
        "        break  \n",
        "\n",
        "    except:\n",
        "        print('Bad MIDI:', f)\n",
        "        continue\n",
        "print('=' * 70)\n",
        "        \n",
        "print('Done!')   \n",
        "print('=' * 70)\n",
        "\n",
        "print('Resulting Stats:')\n",
        "print('=' * 70)\n",
        "\n",
        "print('Piano:', stats[0])\n",
        "print('Guitar:', stats[1])\n",
        "print('Bass:', stats[2])\n",
        "print('Violin:', stats[3])\n",
        "print('Cello:', stats[4])\n",
        "print('Harp:', stats[5])\n",
        "print('Trumpet:', stats[6])\n",
        "print('Clarinet:', stats[7])\n",
        "print('Flute:', stats[8])\n",
        "print('Drums:', stats[9])\n",
        "print('Choir:', stats[10])\n",
        "\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (SAVE/LOAD TRAIN DATA)"
      ],
      "metadata": {
        "id": "-OkybkJp_swb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "3ee97039-6ebe-4896-846c-4564d7ee16cf",
          "kernelId": ""
        },
        "id": "K1kN-St0vFjo"
      },
      "outputs": [],
      "source": [
        "TMIDIX.Tegridy_Any_Pickle_File_Writer(melody_chords_f, '/content/Sparse_Yoda_Training_Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "0553db32-585b-48bc-abd2-8b9aebde5c8f",
          "kernelId": ""
        },
        "id": "pvvCHAUIvFjp"
      },
      "outputs": [],
      "source": [
        "melody_chords_f = TMIDIX.Tegridy_Any_Pickle_File_Reader('/content/Sparse_Yoda_Training_Data')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (PREP INTS)"
      ],
      "metadata": {
        "id": "mWqGLYZx_wzY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "0826f622-2edc-4f09-9a01-58df049738d4",
          "kernelId": ""
        },
        "id": "jKoHDlX_vFjq"
      },
      "outputs": [],
      "source": [
        "# Process and prep INTs...\n",
        "\n",
        "randomize_dataset = True\n",
        "\n",
        "print('=' * 70)\n",
        "print('Prepping INTs dataset...')\n",
        "\n",
        "if randomize_dataset:\n",
        "    print('=' * 70)\n",
        "    print('Randomizing the dataset...')\n",
        "    random.shuffle(melody_chords_f)\n",
        "    print('Done!')\n",
        "    \n",
        "print('=' * 70)\n",
        "print('Processing the dataset...')\n",
        "\n",
        "train_data1 = []\n",
        "\n",
        "for chords_list in tqdm.tqdm(melody_chords_f):\n",
        "\n",
        "    for i in chords_list:\n",
        "\n",
        "        train_data1.extend([i[0], i[1], i[2], i[3], 127]) # [d_start-time / duration / channel / pitch / separator]\n",
        "\n",
        "print('Done!')        \n",
        "print('=' * 70)\n",
        "        \n",
        "print('Total INTs:', len(train_data1))\n",
        "print('Minimum INT:', min(train_data1))\n",
        "print('Maximum INT:', max(train_data1))\n",
        "print('Unique INTs:', len(set(train_data1)))\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (TEST)"
      ],
      "metadata": {
        "id": "kRfJiG6s_3kF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtKg-a-kvFjs"
      },
      "source": [
        "# Test the resulting INTs dataset..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "708f16d3-1747-4e72-bcc9-7504cdd963d4",
          "kernelId": ""
        },
        "id": "1ivJpwLvvFjt"
      },
      "outputs": [],
      "source": [
        "train_data1[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "execution_count": 6,
          "id": "dd411e56-532f-47dd-8283-ecb57126a3ae",
          "kernelId": ""
        },
        "id": "WXEqPMspvFjt"
      },
      "outputs": [],
      "source": [
        "out = train_data1[:16000]\n",
        "\n",
        "if len(out) != 0:\n",
        "    \n",
        "    song = out\n",
        "    song_f = []\n",
        "    time = 0\n",
        "    dur = 0\n",
        "    vel = 0\n",
        "    pitch = 0\n",
        "    channel = 0\n",
        "    son = []\n",
        "\n",
        "    for s in song:\n",
        "        if s != 127:\n",
        "          son.append(s)\n",
        "        else:\n",
        "          time += son[0] * 10\n",
        "\n",
        "          dur = (son[1] * 20) + 20\n",
        "\n",
        "          channel = son[2]\n",
        "\n",
        "          pitch = son[3]\n",
        "          \n",
        "          # Velocities for each channel:\n",
        "          if channel == 0:  # Piano     \n",
        "              vel = 60\n",
        "          if channel == 1:  # Guitar     \n",
        "              vel = 70            \n",
        "          if channel == 2:  # Bass     \n",
        "              vel = 60            \n",
        "          if channel == 3:  # Violin\n",
        "              vel = 90            \n",
        "          if channel == 4:  # Cello     \n",
        "              vel = 100\n",
        "          if channel == 5:  # Harp     \n",
        "              vel = 80\n",
        "          if channel == 6:  # Trumpet     \n",
        "              vel = 100            \n",
        "          if channel == 7:  # Clarinet     \n",
        "              vel = 100           \n",
        "          if channel == 8:  # Flute\n",
        "              vel = 100                          \n",
        "          if channel == 9:  # Drums\n",
        "              vel = 80            \n",
        "          if channel == 10:  # Choir     \n",
        "              vel = 110                  \n",
        "                              \n",
        "          song_f.append(['note', time, dur, channel, pitch, vel ])\n",
        "\n",
        "          son = []\n",
        "\n",
        "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
        "                                                        output_signature = 'Yoda',  \n",
        "                                                        output_file_name = '/content/Sparse-Yoda-Music-Composition', \n",
        "                                                        track_name='Project Los Angeles',\n",
        "                                                        list_of_MIDI_patches=[0, 24, 32, 40, 42, 46, 56, 71, 73, 0, 53, 0, 0, 0, 0, 0],\n",
        "                                                        number_of_ticks_per_quarter=500)\n",
        "\n",
        "    print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (TRAIN)"
      ],
      "metadata": {
        "id": "W7jQDzM8_UZw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9CBW8xYupH8"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the model...\n",
        "\n",
        "# constants\n",
        "\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "NUM_BATCHES = int(len(train_data1) / BATCH_SIZE)\n",
        "\n",
        "GRADIENT_ACCUMULATE_EVERY = 4\n",
        "LEARNING_RATE = 1e-4\n",
        "VALIDATE_EVERY  = 100\n",
        "GENERATE_EVERY  = 200\n",
        "GENERATE_LENGTH = 64\n",
        "SEQ_LEN = 4096\n",
        "\n",
        "# helpers\n",
        "\n",
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "            yield data\n",
        "\n",
        "# instantiate model\n",
        "\n",
        "model = SinkhornTransformerLM(\n",
        "    num_tokens = max(train_data1)+1,\n",
        "    emb_dim = 128,\n",
        "    dim = 1024, # This should be 1/4 of SEQ_LEN\n",
        "    depth = 16, # You can bump this to 24 or 32, depending on your dataset size\n",
        "    max_seq_len = SEQ_LEN,\n",
        "    heads = 16, # You can bump this to 24 or 32, depending on your dataset size\n",
        "    bucket_size = 128,\n",
        "    ff_chunks = 2,\n",
        "    causal = True,\n",
        "    reversible = True,\n",
        "    attn_dropout = 0.1,\n",
        "    n_local_attn_heads = 4\n",
        ")\n",
        "model = AutoregressiveWrapper(model)\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "fgYsqvnK0i6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare training data...\n",
        "\n",
        "X = train_data1\n",
        "trX, vaX = np.split(X, [len(train_data1)-8192])\n",
        "data_train, data_val = torch.from_numpy(trX), torch.from_numpy(vaX)\n",
        "\n",
        "class TextSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len - 1, (1,))\n",
        "        full_seq = self.data[rand_start: rand_start + self.seq_len + 1].long()\n",
        "        return full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE))\n",
        "val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE))\n",
        "\n",
        "# optimizer\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "1zd_EKkq0i2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train...\n",
        "\n",
        "losses = []\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='Training'):\n",
        "    model.train()\n",
        "\n",
        "    for __ in range(GRADIENT_ACCUMULATE_EVERY):\n",
        "        loss = model(next(train_loader), return_loss = True)\n",
        "        losses.append(loss.cpu().tolist())\n",
        "        loss.backward()\n",
        "\n",
        "    # print(f'Training loss: {loss.item()}')\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    if i % VALIDATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            loss = model(next(val_loader), return_loss = True)\n",
        "            print(f'Validation loss: {loss.item()}')\n",
        "            print('Training loss:', losses[-1])\n",
        "\n",
        "    if i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        inp = random.choice(val_dataset)[:-1]\n",
        "        print('Testing...')\n",
        "        print('Input:', inp[-8:])\n",
        "        sample = model.generate(inp, GENERATE_LENGTH)\n",
        "        print('Output:', sample[:8])\n",
        "        print('Done!')\n",
        "        print('LOSS:', losses[-1])\n",
        "\n",
        "    if i % GENERATE_EVERY == 0:\n",
        "      torch.save(model.state_dict(), '/content/Sparse-Yoda-Trained-Model.pth')\n",
        "      tr_loss_list = [item for item in losses]\n",
        "      plt.plot([i for i in range(len(tr_loss_list))] ,tr_loss_list, 'b')\n",
        "      plt.savefig('/content/Sparse-Yoda-Training-Loss-Graph.png')"
      ],
      "metadata": {
        "id": "-cpGAFxR0i0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzCMd94Tu_gz"
      },
      "source": [
        "# Congrats! You did it! :)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Sparse_Yoda_Maker.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}